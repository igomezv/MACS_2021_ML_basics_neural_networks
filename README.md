# MACS 2021. Machine Learning Basics I

La primera parte del curso **Machine Learning Basics** de la [IV Mexican AstroCosmoStatistics School (MACS)](http://fisica.ugto.mx/~events/macss/?fbclid=IwAR1UObd3h7WdAYEb3mFOGypAjqXY1LJH3dJ1x24dMrvGoWeiDskgK2vECDc) consiste en un curso básico y breve sobre Redes Neuronales Artificiales.

**Fecha:** Lunes 28 de junio de 2021. 

**Hora:** 12:00-13:50. y de 16:00-17:20

**Instructores:** José Alberto Vázquez (ICF-UNAM) e Isidro Gómez-Vargas (ICF-UNAM)

**Colaborador:** Juan de Dios Rojas Olvera (Facultad de Ciencias, UNAM)

**Duración:** 70 min + 30 min de preguntas o ejercicios. El mini-curso se divide en tres secciones de 20 min y media hora de práctica.

-----------------------------------
## Requisitos

- Una computadora e Internet. 
- Una cuenta de Google. 

Para evitar instalación de librerías se recomienda [Google Colab](https://colab.research.google.com), el cual es un servicio gratuito de Google para ejecutar *notebooks* en la nube, permitiendo utilizar Python 2 o Python 3 con CPU, GPU y TPU. Solo es necesario tener una cuenta de Google. Para este mini-curso se requiere entorno de ejecución Python 3. 

Desde [Google Colab](https://colab.research.google.com) puedes buscar este repositorio, abrirlo y hacer una copia en tu Google Drive para poder guardar tus cambios. También puedes clonar o descargar el repositorio y abrir las notebooks desde Google Colab. 

**Se recomienda descargar, clonar o acceder al repositorio el día del evento para tener la versión final.**

-----------------------------------

## Plan del mini-curso

**Nota:** Una parte del curso quedó grabada en [youtube](https://www.youtube.com/watch?v=ywZdfz7b1_g).

- 12:00-12:30. Introducción

- 12:30-12:50. Primeras neuronas artificiales ([Notebook 1](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/1-Primeras_neuronas_artificiales.ipynb)).
	
- 12:50-13:20. Red neuronal con diferentes funciones de activacion y propagación de errores hacia atrás (backpropagation). ([Notebook 2](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/2-Red_neuronal_backpropagation.ipynb)).

- 13:20-13:50. Redes neuronales con múltiples capas ([Notebook 3](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/3-Redes_neuronales_keras.ipynb)).

- 16:00-17:20. Sesión de preguntas o trabajar algún ejercicio en grupo. Por votación, se trabajará en alguno de los ejercicios opcionales en la parte final del mini-curso:
	
	1. Compuertas lógicas ([Notebook 1](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/1-Primeras_neuronas_artificiales.ipynb)).
	2. Clasificación lineal ([Notebook 1](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/1-Primeras_neuronas_artificiales.ipynb)).
	3. Aproximar función con red neuronal de una capa ([Notebook 2](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/2-Red_neuronal_backpropagation.ipynb)).
	4. Aprender funciones con redes de múltiples capas y neuronas ([Notebook 3](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/3-Redes_neuronales_keras.ipynb)).
	5. Reducir tiempos ([Notebook 3](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/3-Redes_neuronales_keras.ipynb)).
	6. Modelar datos de Supernovas del tipo IA de la compilación JLA ([Notebook 3](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/3-Redes_neuronales_keras.ipynb)).
	7. Clasificar estrellas, galaxias y cuásares del SDSS-DR14 ([Notebook 1](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/1-Primeras_neuronas_artificiales.ipynb) y [notebook 3](https://github.com/igomezv/MACS_2021_ML_basics_neural_networks/blob/main/3-Redes_neuronales_keras.ipynb)).	

-----------------------------

## Referencias

- Sección 1: 

	- McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4), 115-133. 

	- Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6), 386.

	- https://jontysinai.github.io/jekyll/update/2017/09/24/the-mcp-neuron.html

	- https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html 

- Sección 2:

	- Nielsen, M. A. (2015). Neural networks and deep learning (Vol. 25). San Francisco, CA: Determination press.

	- https://kevinbinz.com/2019/05/26/intro-gradient-descent/

	- https://mlfromscratch.com/activation-functions-explained/#/

	- https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c


- Sección 3:
		
	- https://keras.io/

	- https://igomezv.github.io/2020-10-09-intro-neural/

	- Gómez-Vargas, I., Vázquez, J. A., Esquivel, R. M., & García-Salcedo, R. (2021). Cosmological Reconstructions with Artificial Neural Networks. arXiv preprint arXiv:2104.00595.

	- Gómez-Vargas, I., Esquivel, R. M., García-Salcedo, R., & Vázquez, J. A. (2021). Neural network within a Bayesian inference framework. In Journal of Physics: Conference Series (Vol. 1723, No. 1, p. 012022). IOP Publishing.

	- Vázquez, J. A., Esquivel, R. M., & Gómez-Vargas, I. (2021). Cosmologıa observacional con Redes Neuronales Artificiales. Esta edición fue preparada por el Instituto de Física y el Instituto de Ciencias Físicas de la UNAM., 89.

-----------------------------

## Cartel del evento

![](https://github.com/igomezv/MACS_2021_neural_networks/blob/main/figures/macs.jpg)
